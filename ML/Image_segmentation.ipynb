{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-net\n",
    "============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://arxiv.org/abs/1505.04597\n",
    "#### - U-Net 이라 불리는 인코더(다운샘플링)와 디코더(업샘플링)를 포함한 구조는 정교한 픽셀 단위의 segmentation이 요구되는 biomedical image segmentation task의 핵심 요소\n",
    "#### - Encoder-decoder 구조 또한 semantic segmentation을 위한 CNN 구조를 자주 활용\n",
    "#### - Encoder 부분에서는 encoder에서 점진적으로 spatial dimentsion을 줄여가면서 고차원의 semantic 정보를 convolution filter가 추출 해낼 수 있게 함\n",
    "#### - Decoder 부분에서는 encoder에서 spatial dimension 축소로 인해 손실된 spatial 정보를 점진적으로 복원하여 보다 정교한 boundary segmentation을 완성\n",
    "#### - U-Net은 기본적인 encoder-decoder 구조와 달리 Spatial 정보를 복원하는 과정에서 이전 encoder feature map 중 동일한 크기를 지닌 feature map을 가져와 prior로 활용함으로써 더 정확한 boundary segmentation을 완성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oxford-IIIT Pets 데이터셋\n",
    "- 영상, 해당 레이블과 픽셀 단위의 마스크로 구성\n",
    "- 마스크는 기본적으로 각 픽셀의 레이블\n",
    "- 각 픽셀은 다음 세 가지 범주 중 하나\n",
    "     * class 1 : 애완동물이 속한 픽셀\n",
    "     * class 2 : 애완동물과 인접한 픽셀\n",
    "     * class 3 : 위에 속하지 않는 경우/주변 픽셀\n",
    "- Images: https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
    "- Annotations: https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotation.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
